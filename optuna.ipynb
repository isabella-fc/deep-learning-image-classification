{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4790a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import (Dropout, GlobalAveragePooling2D)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import csv\n",
    "import optuna\n",
    "from utils import *\n",
    "from tensorflow.keras.applications import InceptionV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f13586",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"metadata.csv\"\n",
    "df = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5458ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.TFRecordDataset(paths[\"train\"])\n",
    "train_ds = train_ds.map(parse_record, num_parallel_calls=AUTOTUNE).shuffle(1000).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.TFRecordDataset(paths[\"val\"])\n",
    "val_ds = val_ds.map(parse_record, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(paths[\"test\"])\n",
    "test_ds = test_ds.map(parse_record, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a36b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['phylum'] + '_' + df['family']\n",
    "class_names = sorted(df['label'].unique())\n",
    "class_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "df['label_idx'] = df['label'].map(class_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87811460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(class_names)),\n",
    "    y=df['label_idx']\n",
    ")\n",
    "\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15188ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 01:17:49,188] A new study created in memory with name: no-name-ef69709c-8363-4896-955a-dd7d1dde165c\n",
      "2025-04-26 01:20:10.576970: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-04-26 01:20:41.694616: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-04-26 01:23:45.633388: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-04-26 01:30:38.805986: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-04-26 01:45:24.348303: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "[I 2025-04-26 02:00:54,592] Trial 0 finished with value: 0.5258764624595642 and parameters: {'learning_rate': 0.00032472353735308836, 'dropout_rate': 0.41167144305286724, 'dense_units': 128, 'trainable_layers': 22}. Best is trial 0 with value: 0.5258764624595642.\n",
      "2025-04-26 02:19:38.237459: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "[I 2025-04-26 02:32:05,689] Trial 1 finished with value: 0.4891485869884491 and parameters: {'learning_rate': 0.0006698016935682702, 'dropout_rate': 0.44701425041779613, 'dense_units': 256, 'trainable_layers': 62}. Best is trial 0 with value: 0.5258764624595642.\n",
      "2025-04-26 03:34:10.358733: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "[I 2025-04-26 04:10:07,519] Trial 2 finished with value: 0.4657762944698334 and parameters: {'learning_rate': 2.444882965157271e-05, 'dropout_rate': 0.492059758014198, 'dense_units': 64, 'trainable_layers': 100}. Best is trial 0 with value: 0.5258764624595642.\n",
      "[I 2025-04-26 05:31:06,473] Trial 3 finished with value: 0.5303283333778381 and parameters: {'learning_rate': 3.2746135793812556e-05, 'dropout_rate': 0.480046201127086, 'dense_units': 256, 'trainable_layers': 33}. Best is trial 3 with value: 0.5303283333778381.\n",
      "2025-04-26 05:49:51.149405: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "[I 2025-04-26 06:01:20,018] Trial 4 finished with value: 0.4880356192588806 and parameters: {'learning_rate': 0.0010840459195017528, 'dropout_rate': 0.49420219600102594, 'dense_units': 128, 'trainable_layers': 22}. Best is trial 3 with value: 0.5303283333778381.\n",
      "[I 2025-04-26 06:41:22,372] Trial 5 finished with value: 0.45186421275138855 and parameters: {'learning_rate': 0.0007778220365531988, 'dropout_rate': 0.45363203381378314, 'dense_units': 256, 'trainable_layers': 88}. Best is trial 3 with value: 0.5303283333778381.\n",
      "[I 2025-04-26 07:06:35,696] Trial 6 finished with value: 0.4062325954437256 and parameters: {'learning_rate': 0.002475721600144454, 'dropout_rate': 0.37548712836289666, 'dense_units': 128, 'trainable_layers': 51}. Best is trial 3 with value: 0.5303283333778381.\n",
      "[I 2025-04-26 08:09:11,789] Trial 7 finished with value: 0.5180857181549072 and parameters: {'learning_rate': 7.918424279352866e-05, 'dropout_rate': 0.38209832225435214, 'dense_units': 64, 'trainable_layers': 65}. Best is trial 3 with value: 0.5303283333778381.\n",
      "[I 2025-04-26 09:52:07,716] Trial 8 finished with value: 0.5136338472366333 and parameters: {'learning_rate': 2.6055296681340774e-05, 'dropout_rate': 0.4593022464400049, 'dense_units': 128, 'trainable_layers': 99}. Best is trial 3 with value: 0.5303283333778381.\n",
      "2025-04-26 10:44:36.346722: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "[I 2025-04-26 11:12:42,068] Trial 9 finished with value: 0.4852531850337982 and parameters: {'learning_rate': 1.9275141954031853e-05, 'dropout_rate': 0.39140679854194277, 'dense_units': 128, 'trainable_layers': 31}. Best is trial 3 with value: 0.5303283333778381.\n",
      "[I 2025-04-26 11:58:08,179] Trial 10 finished with value: 0.541458010673523 and parameters: {'learning_rate': 9.1676792212501e-05, 'dropout_rate': 0.29604162348415275, 'dense_units': 256, 'trainable_layers': 41}. Best is trial 10 with value: 0.541458010673523.\n",
      "[I 2025-04-26 12:48:19,867] Trial 11 finished with value: 0.5331107378005981 and parameters: {'learning_rate': 0.0001032239942935305, 'dropout_rate': 0.2870484465589351, 'dense_units': 256, 'trainable_layers': 40}. Best is trial 10 with value: 0.541458010673523.\n",
      "[I 2025-04-26 13:38:42,883] Trial 12 finished with value: 0.549805223941803 and parameters: {'learning_rate': 0.00010884905331456363, 'dropout_rate': 0.27165933145033067, 'dense_units': 256, 'trainable_layers': 45}. Best is trial 12 with value: 0.549805223941803.\n",
      "[I 2025-04-26 14:14:54,381] Trial 13 finished with value: 0.5486922860145569 and parameters: {'learning_rate': 0.00011064246560774725, 'dropout_rate': 0.21644087535079526, 'dense_units': 256, 'trainable_layers': 50}. Best is trial 12 with value: 0.549805223941803.\n",
      "[I 2025-04-26 14:45:54,717] Trial 14 finished with value: 0.2982749044895172 and parameters: {'learning_rate': 0.008956913564049, 'dropout_rate': 0.2101404352528022, 'dense_units': 256, 'trainable_layers': 51}. Best is trial 12 with value: 0.549805223941803.\n",
      "[I 2025-04-26 15:24:26,657] Trial 15 finished with value: 0.5637173056602478 and parameters: {'learning_rate': 0.00022631443241333675, 'dropout_rate': 0.20862506393987143, 'dense_units': 256, 'trainable_layers': 71}. Best is trial 15 with value: 0.5637173056602478.\n",
      "[I 2025-04-26 15:59:53,303] Trial 16 finished with value: 0.5626043677330017 and parameters: {'learning_rate': 0.0002560055310403, 'dropout_rate': 0.26088196070500314, 'dense_units': 256, 'trainable_layers': 76}. Best is trial 15 with value: 0.5637173056602478.\n",
      "[I 2025-04-26 16:35:17,314] Trial 17 finished with value: 0.537006139755249 and parameters: {'learning_rate': 0.00028885954103766875, 'dropout_rate': 0.2512745815533262, 'dense_units': 64, 'trainable_layers': 76}. Best is trial 15 with value: 0.5637173056602478.\n",
      "[I 2025-04-26 17:11:49,168] Trial 18 finished with value: 0.5481357574462891 and parameters: {'learning_rate': 0.0003228527877264957, 'dropout_rate': 0.3206987129394106, 'dense_units': 256, 'trainable_layers': 79}. Best is trial 15 with value: 0.5637173056602478.\n",
      "[I 2025-04-26 17:46:13,110] Trial 19 finished with value: 0.40289372205734253 and parameters: {'learning_rate': 0.0025594008625874722, 'dropout_rate': 0.24402177239910708, 'dense_units': 256, 'trainable_layers': 70}. Best is trial 15 with value: 0.5637173056602478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros:\n",
      "{'learning_rate': 0.00022631443241333675, 'dropout_rate': 0.20862506393987143, 'dense_units': 256, 'trainable_layers': 71}\n"
     ]
    }
   ],
   "source": [
    "def create_model(trial):\n",
    "    # Hiperparâmetros a testar\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    dense_units = trial.suggest_categorical(\"dense_units\", [64, 128, 256])\n",
    "    trainable_layers = trial.suggest_int(\"trainable_layers\", 20, 100)\n",
    "\n",
    "    # Base do modelo\n",
    "    base_model = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Congelar parte das camadas\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dense(202, activation='softmax')  # 202 classes\n",
    "    ])\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Usa a melhor accuracy de validação como objetivo\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  # Faz 20 testes de configurações diferentes\n",
    "\n",
    "# Resultados\n",
    "print(\"Melhores hiperparâmetros:\")\n",
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
